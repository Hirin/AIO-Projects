# So SÃ¡nh: Baseline BTC vs Phase 3 VideoMAE

> **TÃ i liá»‡u so sÃ¡nh chi tiáº¿t** giá»¯a hai approaches cho bÃ i toÃ¡n Video Action Recognition trÃªn HMDB51.

---

## ğŸ“Š Tá»•ng Quan So SÃ¡nh

| Aspect | Baseline BTC | Phase 3 VideoMAE |
|--------|--------------|------------------|
| **Model** | ViT-Small | VideoMAE-Base |
| **Pretrain Data** | ImageNet (Images) | Kinetics-400 (Videos) |
| **Parameters** | ~22M | ~86M |
| **Training Time** | ~21 phÃºt | ~6.8 giá» |
| **Epochs** | 4 | 40 (30+10) |
| **Expected Accuracy** | ~0.65-0.70 | >0.83 |

---

## ğŸ—ï¸ Kiáº¿n TrÃºc Model

### Baseline: LightweightViTForAction

```
Input [B, 16, 3, 224, 224]
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ViT-Small     â”‚  â† ImageNet pretrained
â”‚  (per-frame)    â”‚  â† Xá»­ lÃ½ tá»«ng frame Ä‘á»™c láº­p
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
    Mean Pooling      â† Chá»‰ average, khÃ´ng há»c temporal
         â”‚
         â–¼
    Linear(384, 51)
         â”‚
         â–¼
    Output [B, 51]
```

### Phase 3: VideoMAE

```
Input [B, 16, 3, 224, 224]
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    VideoMAE     â”‚  â† Kinetics-400 pretrained
â”‚   Encoder       â”‚  â† Temporal + Spatial Attention
â”‚                 â”‚  â† Masked Autoencoder pretraining
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
    Built-in Pooling  â† Learned temporal aggregation
         â”‚
         â–¼
    Linear(768, 51)
         â”‚
         â–¼
    Output [B, 51]
```

### Äiá»ƒm KhÃ¡c Biá»‡t ChÃ­nh

| Component | Baseline | Phase 3 |
|-----------|----------|---------|
| **Backbone** | `vit_small_patch16_224` | `videomae-base-finetuned-kinetics` |
| **Hidden Dim** | 384 | 768 |
| **Temporal Modeling** | Mean Pool (no learning) | Temporal Attention (learned) |
| **Pretrain Task** | Image Classification | Video Masked Autoencoding |

---

## âš™ï¸ Hyperparameters

| Parameter | Baseline | Phase 3 |
|-----------|----------|---------|
| **Batch Size** | 16 | 8 |
| **Effective Batch** | 64 (accum=4) | 32 (accum=4) |
| **Learning Rate** | 1e-4 (backbone), 5e-4 (head) | 5e-5 (P1), 1e-6 (P2) |
| **Weight Decay** | 0.05 | 0.05 |
| **Epochs** | 4 | 40 (30+10) |
| **Optimizer** | AdamW | AdamW |
| **LR Schedule** | None | Cosine + Warmup |
| **Warmup** | None | 10% |

---

## ğŸ“Š Data Augmentation

### Baseline

```python
# Training
â”œâ”€â”€ Random Scale (0.8-1.0)
â”œâ”€â”€ Random Crop â†’ 224x224
â”œâ”€â”€ Random H-Flip (p=0.5)
â””â”€â”€ Normalize (mean=0.5, std=0.5)

# âš ï¸ KHÃ”NG consistent across frames
# âš ï¸ Má»—i frame cÃ³ thá»ƒ crop/flip khÃ¡c nhau
```

### Phase 3

```python
# Training
â”œâ”€â”€ Resize short edge â†’ 256
â”œâ”€â”€ RandomResizedCrop (scale=0.8-1.0, ratio=0.75-1.33)
â”œâ”€â”€ Random H-Flip (p=0.5)
â”œâ”€â”€ Normalize (VideoMAE mean/std)
â””â”€â”€ Mixup (Î±=0.8, prob=1.0)  # Phase 1 only

# âœ… CONSISTENT across frames
# âœ… CÃ¹ng crop params cho táº¥t cáº£ frames trong video
```

### So SÃ¡nh Chi Tiáº¿t

| Augmentation | Baseline | Phase 3 |
|--------------|----------|---------|
| **Random Crop** | âœ… | âœ… (Consistent) |
| **Horizontal Flip** | âœ… | âœ… (Consistent) |
| **Consistent Transform** | âŒ | âœ… |
| **Mixup** | âŒ | âœ… (Phase 1) |
| **Label Smoothing** | âŒ | âœ… (Phase 2) |
| **Resize Strategy** | Direct to 224 | Short edge 256 â†’ Crop 224 |

---

## ğŸ‹ï¸ Training Strategy

### Baseline: Single-Phase Training

```
Epoch 1 â”€â”€â–º Epoch 2 â”€â”€â–º Epoch 3 â”€â”€â–º Epoch 4 â”€â”€â–º Done
   â”‚           â”‚           â”‚           â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         Constant Strategy Throughout
         
â€¢ Fixed LR: 1e-4 / 5e-4
â€¢ No augmentation changes
â€¢ Cross-Entropy loss
```

### Phase 3: 2-Stage Training

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           PHASE 1 (30 epochs)       â”‚
â”‚  â€¢ Mixup ON (Î±=0.8)                 â”‚
â”‚  â€¢ Higher LR (5e-5)                 â”‚
â”‚  â€¢ Cosine Schedule + Warmup         â”‚
â”‚  â€¢ Soft Cross-Entropy Loss          â”‚
â”‚  â†’ Learn robust, diverse features   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼ Load Best P1 Model
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           PHASE 2 (10 epochs)       â”‚
â”‚  â€¢ Mixup OFF                        â”‚
â”‚  â€¢ Label Smoothing (0.1)            â”‚
â”‚  â€¢ Very Low LR (1e-6)               â”‚
â”‚  â€¢ Standard Cross-Entropy           â”‚
â”‚  â†’ Polish without overfitting       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ” Inference

### Baseline: Single-View

```
Video â”€â”€â–º Resize 224 â”€â”€â–º Model â”€â”€â–º Prediction
                â”‚
           1 forward pass
```

### Phase 3: 6-View TTA

```
Video â”€â”€â”¬â”€â”€â–º Center Crop â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â–º Model â”€â”€â”
        â”œâ”€â”€â–º Left/Top Crop â”€â”€â”€â”€â”€â”¤             â”‚
        â”œâ”€â”€â–º Right/Bottom Crop â”€â”¤             â”‚
        â”œâ”€â”€â–º Center + Flip â”€â”€â”€â”€â”€â”¤             â”œâ”€â”€â–º Average â”€â”€â–º Prediction
        â”œâ”€â”€â–º Left/Top + Flip â”€â”€â”€â”¤             â”‚
        â””â”€â”€â–º Right/Bottom + Flipâ”˜             â”‚
                â”‚                             â”‚
           6 forward passes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

### Comparison

| Aspect | Baseline | Phase 3 |
|--------|----------|---------|
| **Views** | 1 | 6 |
| **Crops** | Center only | Center + Side crops |
| **Flips** | No | Yes (all crops) |
| **Aggregation** | N/A | Average logits |
| **Robustness** | Low | High |
| **Inference Time** | 1x | ~6x |

---

## ğŸ“ˆ Ká»¹ Thuáº­t Regularization

| Technique | Baseline | Phase 3 | Má»¥c ÄÃ­ch |
|-----------|----------|---------|----------|
| **Mixup** | âŒ | âœ… | Smooth decision boundaries |
| **Label Smoothing** | âŒ | âœ… | Prevent overconfidence |
| **Weight Decay** | âœ… 0.05 | âœ… 0.05 | L2 regularization |
| **Gradient Clipping** | âŒ | âœ… max=1.0 | Training stability |
| **Dropout** | âŒ | Built-in | Prevent overfitting |

---

## ğŸ’» Code Comparison

### Model Loading

**Baseline:**
```python
import timm
model = timm.create_model('vit_small_patch16_224', pretrained=True, num_classes=0)
head = nn.Linear(384, 51)
```

**Phase 3:**
```python
from transformers import VideoMAEForVideoClassification
model = VideoMAEForVideoClassification.from_pretrained(
    "MCG-NJU/videomae-base-finetuned-kinetics",
    label2id=label2id,
    id2label=id2label,
    ignore_mismatched_sizes=True,
    num_frames=16
)
```

### Loss Function

**Baseline:**
```python
loss = F.cross_entropy(logits, labels)
```

**Phase 3:**
```python
# Phase 1: Soft CE for Mixup
if use_mixup:
    log_probs = F.log_softmax(logits, dim=1)
    loss = -torch.sum(targets * log_probs, dim=1).mean()
# Phase 2: CE with Label Smoothing
else:
    loss = F.cross_entropy(logits, targets, label_smoothing=0.1)
```

### Data Transform

**Baseline:**
```python
class VideoTransform:
    def __call__(self, frames):
        # Each frame transformed independently
        for frame in frames:
            frame = random_crop(frame)  # Different for each frame!
            frame = maybe_flip(frame)   # Different for each frame!
```

**Phase 3:**
```python
class VideoDataset:
    def __getitem__(self, idx):
        # Get params ONCE for entire video
        i, j, h, w = RandomResizedCrop.get_params(frames[0], ...)
        is_flip = random.random() > 0.5
        
        # Apply SAME transform to ALL frames
        for img in frames:
            img = TF.resized_crop(img, i, j, h, w, ...)
            if is_flip:
                img = TF.hflip(img)
```

---

## ğŸ“Š Expected Performance

```
                    Accuracy
    0.5   0.6   0.7   0.8   0.9   1.0
     â”‚     â”‚     â”‚     â”‚     â”‚     â”‚
     â”œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¤
     â”‚           â”‚           â”‚     â”‚
     â”‚  Baseline â”‚           â”‚     â”‚
     â”‚  (0.65-0.70)          â”‚     â”‚
     â”‚           â”‚           â”‚     â”‚
     â”‚           â”‚   Phase 3 â”‚     â”‚
     â”‚           â”‚   (>0.83) â”‚     â”‚
     â”‚           â”‚           â”‚     â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Khi NÃ o DÃ¹ng GÃ¬?

### DÃ¹ng Baseline Khi:
- âœ… Prototype nhanh, test pipeline
- âœ… Limited compute resources
- âœ… Baseline comparison
- âœ… Há»c vá» video classification cÆ¡ báº£n

### DÃ¹ng Phase 3 Khi:
- âœ… Cáº§n accuracy cao
- âœ… CÃ³ Ä‘á»§ GPU time (~7 giá»)
- âœ… Competition/Production
- âœ… Dataset video action recognition

---

## ğŸ“ Summary

| Aspect | Winner | Reason |
|--------|--------|--------|
| **Accuracy** | Phase 3 | VideoMAE + advanced techniques |
| **Speed** | Baseline | 20x faster training |
| **Simplicity** | Baseline | Fewer components |
| **Robustness** | Phase 3 | Mixup + TTA + Label Smoothing |
| **Temporal Learning** | Phase 3 | Temporal attention vs mean pool |
| **Resource Efficiency** | Baseline | Smaller model, less memory |

---

## ğŸ”„ Improvement Path

```
Baseline BTC
     â”‚
     â”œâ”€â”€â–º Add Consistent Transforms
     â”‚
     â”œâ”€â”€â–º Increase Epochs (4 â†’ 20)
     â”‚
     â”œâ”€â”€â–º Add Learning Rate Schedule
     â”‚
     â”œâ”€â”€â–º Add Mixup
     â”‚
     â”œâ”€â”€â–º Switch to Video Pretrained Model
     â”‚
     â”œâ”€â”€â–º Add 2-Stage Training
     â”‚
     â”œâ”€â”€â–º Add Multi-View TTA
     â”‚
     â–¼
Phase 3 VideoMAE
```
