{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# VideoMAE + RandAugment (Option A)\n",
        "\n",
        "**Strategy:**\n",
        "1. VideoRandAugment for strong data augmentation\n",
        "2. Standard Cross Entropy (NO Mixup, NO Focal Loss)\n",
        "3. 2-Stage Training: RandAugment \u2192 Label Smoothing\n",
        "4. Test evaluation + History tracking + Plots\n",
        "\n",
        "**Target:** \u2265 85% Test Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "!pip install -q transformers accelerate evaluate gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms.functional as TF\n",
        "from transformers import VideoMAEForVideoClassification\n",
        "from transformers import get_cosine_schedule_with_warmup\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from tqdm.auto import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "import random\n",
        "import os\n",
        "import gc\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {DEVICE}')\n",
        "\n",
        "# Paths\n",
        "PATH_DATA_TRAIN = '/kaggle/input/action-video/data/data_train'\n",
        "PATH_DATA_TEST = '/kaggle/input/action-video/data/test'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Model Config\n",
        "MODEL_CKPT = 'MCG-NJU/videomae-base-finetuned-kinetics'\n",
        "NUM_FRAMES = 16\n",
        "IMG_SIZE = 224\n",
        "RESIZE_SIZE = 256\n",
        "\n",
        "# Phase 1 Config (RandAugment)\n",
        "EPOCHS_P1 = 30\n",
        "LR_P1 = 5e-5\n",
        "RANDAUG_NUM_OPS = 2\n",
        "RANDAUG_MAGNITUDE = 9\n",
        "\n",
        "# Phase 2 Config (Label Smoothing)\n",
        "EPOCHS_P2 = 10\n",
        "LR_P2 = 1e-6\n",
        "LABEL_SMOOTHING = 0.1\n",
        "\n",
        "# Common Config\n",
        "BATCH_SIZE = 8\n",
        "ACCUM_STEPS = 4\n",
        "WEIGHT_DECAY = 0.05\n",
        "WARMUP_RATIO = 0.1\n",
        "\n",
        "# Normalization\n",
        "MEAN = [0.485, 0.456, 0.406]\n",
        "STD = [0.229, 0.224, 0.225]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. VideoRandAugment Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "class VideoRandAugment:\n",
        "    \"\"\"\n",
        "    RandAugment for video clips.\n",
        "    Applies SAME random augmentation policy to ALL frames in a clip.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_ops=2, magnitude=9):\n",
        "        self.num_ops = num_ops\n",
        "        self.magnitude = magnitude\n",
        "        \n",
        "        # Define augmentation operations\n",
        "        self.ops = [\n",
        "            ('AutoContrast', lambda img, m: TF.autocontrast(img)),\n",
        "            ('Equalize', lambda img, m: TF.equalize(img)),\n",
        "            ('Solarize', lambda img, m: TF.solarize(img, int(256 - m * 25.6))),\n",
        "            ('Color', lambda img, m: TF.adjust_saturation(img, max(0.1, 1 + m / 10 - 0.5))),\n",
        "            ('Contrast', lambda img, m: TF.adjust_contrast(img, max(0.1, 1 + m / 10 - 0.5))),\n",
        "            ('Brightness', lambda img, m: TF.adjust_brightness(img, max(0.1, 1 + m / 10 - 0.5))),\n",
        "            ('Sharpness', lambda img, m: TF.adjust_sharpness(img, max(0.1, 1 + m / 10 - 0.5))),\n",
        "        ]\n",
        "    \n",
        "    def __call__(self, frames):\n",
        "        \"\"\"\n",
        "        Apply SAME random augmentation to all frames.\n",
        "        \n",
        "        Args:\n",
        "            frames: List of PIL Images\n",
        "        Returns:\n",
        "            augmented_frames: List of augmented PIL Images\n",
        "        \"\"\"\n",
        "        # Sample operations ONCE for this video clip\n",
        "        selected_ops = random.sample(self.ops, k=min(self.num_ops, len(self.ops)))\n",
        "        magnitude = random.uniform(0, self.magnitude)\n",
        "        \n",
        "        # Apply SAME ops with SAME magnitude to ALL frames\n",
        "        augmented_frames = []\n",
        "        for frame in frames:\n",
        "            for op_name, op_func in selected_ops:\n",
        "                try:\n",
        "                    frame = op_func(frame, magnitude)\n",
        "                except:\n",
        "                    pass  # Skip if operation fails\n",
        "            augmented_frames.append(frame)\n",
        "        \n",
        "        return augmented_frames\n",
        "\n",
        "print('VideoRandAugment class defined')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Dataset Classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "class VideoDataset(Dataset):\n",
        "    def __init__(self, root, num_frames=16, is_train=True, use_randaug=True):\n",
        "        self.root = Path(root)\n",
        "        self.num_frames = num_frames\n",
        "        self.is_train = is_train\n",
        "        self.classes = sorted([d.name for d in self.root.iterdir() if d.is_dir()])\n",
        "        self.class_to_idx = {c: i for i, c in enumerate(self.classes)}\n",
        "        self.samples = []\n",
        "        for cls in self.classes:\n",
        "            cls_dir = self.root / cls\n",
        "            for video_dir in sorted([d for d in cls_dir.iterdir() if d.is_dir()]):\n",
        "                self.samples.append((video_dir, self.class_to_idx[cls]))\n",
        "        \n",
        "        # RandAugment\n",
        "        self.video_aug = VideoRandAugment(RANDAUG_NUM_OPS, RANDAUG_MAGNITUDE) if (is_train and use_randaug) else None\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        video_dir, label = self.samples[idx]\n",
        "        frame_paths = sorted(video_dir.glob('*.jpg'))\n",
        "        indices = np.linspace(0, len(frame_paths) - 1, self.num_frames, dtype=int)\n",
        "        frames = [Image.open(frame_paths[i]).convert('RGB') for i in indices]\n",
        "        \n",
        "        if self.is_train:\n",
        "            # 1. Apply RandAugment (SAME policy for all frames)\n",
        "            if self.video_aug:\n",
        "                frames = self.video_aug(frames)\n",
        "            \n",
        "            # 2. Resize\n",
        "            frames = [TF.resize(img, RESIZE_SIZE) for img in frames]\n",
        "            \n",
        "            # 3. Get random crop params ONCE\n",
        "            i, j, h, w = T.RandomResizedCrop.get_params(frames[0], (0.8, 1.0), (0.75, 1.33))\n",
        "            do_flip = random.random() > 0.5\n",
        "            \n",
        "            # 4. Apply SAME crop and flip to all frames\n",
        "            processed = []\n",
        "            for img in frames:\n",
        "                img = TF.resized_crop(img, i, j, h, w, (IMG_SIZE, IMG_SIZE))\n",
        "                if do_flip:\n",
        "                    img = TF.hflip(img)\n",
        "                img = TF.normalize(TF.to_tensor(img), MEAN, STD)\n",
        "                processed.append(img)\n",
        "        else:\n",
        "            # Test: Simple center crop\n",
        "            frames = [TF.resize(img, RESIZE_SIZE) for img in frames]\n",
        "            processed = [TF.normalize(TF.to_tensor(TF.center_crop(img, IMG_SIZE)), MEAN, STD) for img in frames]\n",
        "        \n",
        "        return torch.stack(processed), label\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, root, num_frames=16):\n",
        "        self.root = Path(root)\n",
        "        self.num_frames = num_frames\n",
        "        self.samples = sorted([(d, int(d.name)) for d in self.root.iterdir() if d.is_dir()], key=lambda x: x[1])\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        video_dir, video_id = self.samples[idx]\n",
        "        frame_paths = sorted(video_dir.glob('*.jpg'))\n",
        "        indices = np.linspace(0, len(frame_paths) - 1, self.num_frames, dtype=int)\n",
        "        frames = [TF.resize(Image.open(frame_paths[i]).convert('RGB'), RESIZE_SIZE) for i in indices]\n",
        "        processed = [TF.normalize(TF.to_tensor(TF.center_crop(img, IMG_SIZE)), MEAN, STD) for img in frames]\n",
        "        return torch.stack(processed), video_id\n",
        "\n",
        "print('Dataset classes defined')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Load Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Download test labels\n",
        "!gdown \"1Xv2CWOqdBj3kt0rkNJKRsodSIEd3-wX_\" -O test_labels.csv -q\n",
        "\n",
        "# Load datasets\n",
        "train_dataset_p1 = VideoDataset(PATH_DATA_TRAIN, NUM_FRAMES, is_train=True, use_randaug=True)\n",
        "train_dataset_p2 = VideoDataset(PATH_DATA_TRAIN, NUM_FRAMES, is_train=True, use_randaug=False)  # No aug in P2\n",
        "test_dataset = TestDataset(PATH_DATA_TEST, NUM_FRAMES)\n",
        "\n",
        "# Ground truth\n",
        "gt_df = pd.read_csv('test_labels.csv')\n",
        "gt_dict = dict(zip(gt_df['id'].astype(str), gt_df['class']))\n",
        "\n",
        "print(f'Train samples: {len(train_dataset_p1)}')\n",
        "print(f'Test samples: {len(test_dataset)}')\n",
        "print(f'Classes: {len(train_dataset_p1.classes)}')\n",
        "\n",
        "# DataLoaders\n",
        "train_loader_p1 = DataLoader(train_dataset_p1, BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True, drop_last=True)\n",
        "train_loader_p2 = DataLoader(train_dataset_p2, BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True, drop_last=True)\n",
        "test_loader = DataLoader(test_dataset, BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "print('DataLoaders created')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Load model\n",
        "model = VideoMAEForVideoClassification.from_pretrained(\n",
        "    MODEL_CKPT,\n",
        "    num_labels=len(train_dataset_p1.classes),\n",
        "    ignore_mismatched_sizes=True,\n",
        "    num_frames=NUM_FRAMES\n",
        ").to(DEVICE)\n",
        "print('Model loaded')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Training & Evaluation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "def train_epoch(model, loader, optimizer, scheduler, scaler, label_smoothing=0.0):\n",
        "    model.train()\n",
        "    total_loss, total_correct, total_samples = 0.0, 0, 0\n",
        "    pbar = tqdm(loader, desc='Training', leave=False)\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    for step, (inputs, targets) in enumerate(pbar):\n",
        "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "        \n",
        "        with torch.amp.autocast('cuda'):\n",
        "            logits = model(inputs).logits\n",
        "            loss = F.cross_entropy(logits, targets, label_smoothing=label_smoothing)\n",
        "        \n",
        "        total_correct += (logits.argmax(1) == targets).sum().item()\n",
        "        total_samples += inputs.size(0)\n",
        "        \n",
        "        scaler.scale(loss / ACCUM_STEPS).backward()\n",
        "        \n",
        "        if (step + 1) % ACCUM_STEPS == 0:\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad()\n",
        "            scheduler.step()\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "        pbar.set_postfix({'loss': f'{total_loss/(step+1):.4f}', 'acc': f'{total_correct/total_samples:.4f}'})\n",
        "    \n",
        "    return total_loss / len(loader), total_correct / total_samples\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, classes, gt_dict):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    for videos, video_ids in tqdm(loader, desc='Evaluating', leave=False):\n",
        "        videos = videos.to(DEVICE)\n",
        "        preds = model(videos).logits.argmax(1).cpu().tolist()\n",
        "        predictions.extend(zip(video_ids.tolist(), preds))\n",
        "    \n",
        "    y_true = [gt_dict[str(vid)] for vid, _ in predictions]\n",
        "    y_pred = [classes[p] for _, p in predictions]\n",
        "    return accuracy_score(y_true, y_pred)\n",
        "\n",
        "print('Training functions defined')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Initialize\n",
        "history = []\n",
        "best_acc = 0.0\n",
        "scaler = torch.amp.GradScaler()\n",
        "\n",
        "# Phase 1: RandAugment\n",
        "print('=' * 50)\n",
        "print(f'PHASE 1: RandAugment Training (Epochs: {EPOCHS_P1}, LR: {LR_P1})')\n",
        "print('=' * 50)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR_P1, weight_decay=WEIGHT_DECAY)\n",
        "total_steps = len(train_loader_p1) * EPOCHS_P1 // ACCUM_STEPS\n",
        "scheduler = get_cosine_schedule_with_warmup(optimizer, int(total_steps * WARMUP_RATIO), total_steps)\n",
        "\n",
        "for epoch in range(1, EPOCHS_P1 + 1):\n",
        "    loss, train_acc = train_epoch(model, train_loader_p1, optimizer, scheduler, scaler, label_smoothing=0.0)\n",
        "    test_acc = evaluate(model, test_loader, train_dataset_p1.classes, gt_dict)\n",
        "    \n",
        "    history.append({'epoch': epoch, 'phase': 1, 'loss': loss, 'train_acc': train_acc, 'test_acc': test_acc})\n",
        "    \n",
        "    status = '>>> BEST' if test_acc > best_acc else ''\n",
        "    if test_acc > best_acc:\n",
        "        best_acc = test_acc\n",
        "        torch.save(model.state_dict(), 'best_p1.pt')\n",
        "    print(f'Ep {epoch}/{EPOCHS_P1}: L={loss:.4f} TrAcc={train_acc:.4f} TeAcc={test_acc:.4f} {status}')\n",
        "    \n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# Phase 2: Label Smoothing\n",
        "print('\\n' + '=' * 50)\n",
        "print(f'PHASE 2: Label Smoothing (Epochs: {EPOCHS_P2}, LR: {LR_P2})')\n",
        "print('=' * 50)\n",
        "\n",
        "model.load_state_dict(torch.load('best_p1.pt'))\n",
        "scaler = torch.amp.GradScaler()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR_P2, weight_decay=WEIGHT_DECAY)\n",
        "total_steps = len(train_loader_p2) * EPOCHS_P2 // ACCUM_STEPS\n",
        "scheduler = get_cosine_schedule_with_warmup(optimizer, int(total_steps * WARMUP_RATIO), total_steps)\n",
        "\n",
        "for epoch in range(1, EPOCHS_P2 + 1):\n",
        "    loss, train_acc = train_epoch(model, train_loader_p2, optimizer, scheduler, scaler, label_smoothing=LABEL_SMOOTHING)\n",
        "    test_acc = evaluate(model, test_loader, train_dataset_p1.classes, gt_dict)\n",
        "    \n",
        "    history.append({'epoch': EPOCHS_P1 + epoch, 'phase': 2, 'loss': loss, 'train_acc': train_acc, 'test_acc': test_acc})\n",
        "    \n",
        "    status = '>>> BEST' if test_acc > best_acc else ''\n",
        "    if test_acc > best_acc:\n",
        "        best_acc = test_acc\n",
        "        torch.save(model.state_dict(), 'best_final.pt')\n",
        "    print(f'P2 Ep {epoch}/{EPOCHS_P2}: L={loss:.4f} TrAcc={train_acc:.4f} TeAcc={test_acc:.4f} {status}')\n",
        "    \n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# Save history\n",
        "df_history = pd.DataFrame(history)\n",
        "df_history.to_csv('training_history.csv', index=False)\n",
        "print(f'\\nTraining Complete! Best Test Acc: {best_acc:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##7. Plot Training Curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "df = pd.read_csv('training_history.csv')\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "# Test Accuracy\n",
        "axes[0].plot(df['epoch'], df['test_acc'], 'b-o', markersize=4, label='Test Acc')\n",
        "axes[0].axvline(x=EPOCHS_P1, color='gray', linestyle='--', alpha=0.5, label='P1\u2192P2')\n",
        "axes[0].axhline(y=0.851, color='red', linestyle='--', alpha=0.5, label='Baseline (85.1%)')\n",
        "axes[0].set_title('Test Accuracy')\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('Accuracy')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Train Accuracy\n",
        "axes[1].plot(df['epoch'], df['train_acc'], 'g-s', markersize=4, label='Train Acc')\n",
        "axes[1].axvline(x=EPOCHS_P1, color='gray', linestyle='--', alpha=0.5, label='P1\u2192P2')\n",
        "axes[1].set_title('Train Accuracy')\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_ylabel('Accuracy')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "# Loss\n",
        "axes[2].plot(df['epoch'], df['loss'], 'r-^', markersize=4, label='Loss')\n",
        "axes[2].axvline(x=EPOCHS_P1, color='gray', linestyle='--', alpha=0.5, label='P1\u2192P2')\n",
        "axes[2].set_title('Loss')\n",
        "axes[2].set_xlabel('Epoch')\n",
        "axes[2].set_ylabel('Loss')\n",
        "axes[2].legend()\n",
        "axes[2].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('training_curves.png', dpi=150)\n",
        "plt.show()\n",
        "\n",
        "print('\\n' + '=' * 50)\n",
        "print('TRAINING SUMMARY')\n",
        "print('=' * 50)\n",
        "print(df.to_string(index=False))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}