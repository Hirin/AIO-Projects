{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# VideoMAE 8-Frame: Single Checkpoint Resume"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "import os\n",
                "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
                "import logging\n",
                "logging.getLogger('transformers').setLevel(logging.ERROR)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q transformers accelerate"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn.functional as F\n",
                "from torch.utils.data import DataLoader, Dataset\n",
                "import torchvision.transforms as T\n",
                "import torchvision.transforms.functional as TF\n",
                "from transformers import VideoMAEForVideoClassification, VideoMAEImageProcessor\n",
                "from transformers import get_cosine_schedule_with_warmup\n",
                "from pathlib import Path\n",
                "from PIL import Image\n",
                "from tqdm.auto import tqdm\n",
                "import numpy as np\n",
                "import random\n",
                "import pandas as pd\n",
                "from sklearn.metrics import accuracy_score\n",
                "import matplotlib.pyplot as plt\n",
                "import gc\n",
                "\n",
                "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f'Device: {DEVICE}')\n",
                "\n",
                "PATH_DATA_TRAIN = '/kaggle/input/action-video/data/data_train'\n",
                "PATH_DATA_TEST = '/kaggle/input/action-video/data/test'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!gdown \"1Xv2CWOqdBj3kt0rkNJKRsodSIEd3-wX_\" -O test_labels.csv -q\n",
                "gt_df = pd.read_csv(\"test_labels.csv\")\n",
                "TEST_LABELS = dict(zip(gt_df['id'].astype(str), gt_df['class']))\n",
                "del gt_df; gc.collect()\n",
                "print(f\"Test labels: {len(TEST_LABELS)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Config"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "MODEL_CKPT = \"MCG-NJU/videomae-base-finetuned-kinetics\"\n",
                "NUM_FRAMES = 8\n",
                "IMG_SIZE = 224\n",
                "RESIZE_SIZE = 256\n",
                "\n",
                "EPOCHS_P1 = 30\n",
                "EPOCHS_P2 = 10\n",
                "LR_P1 = 5e-5\n",
                "LR_P2 = 1e-6\n",
                "LABEL_SMOOTHING = 0.1\n",
                "\n",
                "BATCH_SIZE = 32\n",
                "NUM_WORKERS = 4\n",
                "WEIGHT_DECAY = 0.05\n",
                "MIXUP_ALPHA = 0.8\n",
                "\n",
                "print(f\"LR_P1={LR_P1}, LR_P2={LR_P2}, BATCH={BATCH_SIZE}, WORKERS={NUM_WORKERS}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "image_processor = VideoMAEImageProcessor.from_pretrained(MODEL_CKPT)\n",
                "MEAN, STD = image_processor.image_mean, image_processor.image_std\n",
                "\n",
                "class MixupCollate:\n",
                "    def __init__(self, num_classes, alpha=0.8):\n",
                "        self.num_classes, self.alpha = num_classes, alpha\n",
                "    def __call__(self, batch):\n",
                "        inputs, targets = torch.utils.data.default_collate(batch)\n",
                "        lam = np.random.beta(self.alpha, self.alpha)\n",
                "        idx = torch.randperm(inputs.size(0))\n",
                "        inputs = lam * inputs + (1 - lam) * inputs[idx]\n",
                "        oh = F.one_hot(targets, self.num_classes).float()\n",
                "        return inputs, lam * oh + (1 - lam) * oh[idx]\n",
                "\n",
                "class VideoDataset(Dataset):\n",
                "    def __init__(self, root, num_frames=8, is_train=True):\n",
                "        self.root, self.num_frames, self.is_train = Path(root), num_frames, is_train\n",
                "        self.classes = sorted([d.name for d in self.root.iterdir() if d.is_dir()])\n",
                "        self.class_to_idx = {c: i for i, c in enumerate(self.classes)}\n",
                "        self.samples = [(list(sorted(v.glob('*.jpg'))), self.class_to_idx[c]) \n",
                "                        for c in self.classes for v in (self.root/c).iterdir() if v.is_dir()]\n",
                "    def __len__(self): return len(self.samples)\n",
                "    def __getitem__(self, idx):\n",
                "        paths, label = self.samples[idx]\n",
                "        indices = np.linspace(0, len(paths)-1, self.num_frames, dtype=int)\n",
                "        frames = [TF.resize(Image.open(paths[i]).convert('RGB'), RESIZE_SIZE) for i in indices]\n",
                "        if self.is_train:\n",
                "            i,j,h,w = T.RandomResizedCrop.get_params(frames[0], (0.8,1.0), (0.75,1.33))\n",
                "            flip = random.random() > 0.5\n",
                "            frames = [TF.normalize(TF.to_tensor(TF.hflip(TF.resized_crop(f,i,j,h,w,(IMG_SIZE,IMG_SIZE))) if flip else TF.resized_crop(f,i,j,h,w,(IMG_SIZE,IMG_SIZE))), MEAN, STD) for f in frames]\n",
                "        else:\n",
                "            frames = [TF.normalize(TF.to_tensor(TF.center_crop(f, IMG_SIZE)), MEAN, STD) for f in frames]\n",
                "        return torch.stack(frames), label\n",
                "\n",
                "class TestDataset(Dataset):\n",
                "    def __init__(self, root, num_frames=8):\n",
                "        self.root, self.num_frames = Path(root), num_frames\n",
                "        self.videos = sorted([d for d in self.root.iterdir() if d.is_dir()], key=lambda x: int(x.name))\n",
                "    def __len__(self): return len(self.videos)\n",
                "    def __getitem__(self, idx):\n",
                "        v = self.videos[idx]\n",
                "        paths = sorted(v.glob('*.jpg'))\n",
                "        indices = np.linspace(0, len(paths)-1, self.num_frames, dtype=int)\n",
                "        frames = [TF.normalize(TF.to_tensor(TF.center_crop(TF.resize(Image.open(paths[i]).convert('RGB'), RESIZE_SIZE), IMG_SIZE)), MEAN, STD) for i in indices]\n",
                "        return torch.stack(frames), int(v.name)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_dataset = VideoDataset(PATH_DATA_TRAIN, NUM_FRAMES, is_train=True)\n",
                "test_dataset = TestDataset(PATH_DATA_TEST, NUM_FRAMES)\n",
                "print(f\"Train: {len(train_dataset)} | Test: {len(test_dataset)} | Classes: {len(train_dataset.classes)}\")\n",
                "\n",
                "mixup_collate = MixupCollate(len(train_dataset.classes), MIXUP_ALPHA)\n",
                "train_loader_p1 = DataLoader(train_dataset, BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True, collate_fn=mixup_collate, drop_last=True)\n",
                "train_loader_p2 = DataLoader(train_dataset, BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True, drop_last=True)\n",
                "test_loader = DataLoader(test_dataset, BATCH_SIZE, num_workers=NUM_WORKERS, pin_memory=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = VideoMAEForVideoClassification.from_pretrained(\n",
                "    MODEL_CKPT, num_labels=len(train_dataset.classes), \n",
                "    ignore_mismatched_sizes=True, num_frames=NUM_FRAMES\n",
                ").to(DEVICE)\n",
                "print(f\"Params: {sum(p.numel() for p in model.parameters()):,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Training Functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def train_epoch(model, loader, optimizer, scheduler, scaler, use_mixup=True, label_smoothing=0.0):\n",
                "    model.train()\n",
                "    total_loss, correct, total = 0.0, 0, 0\n",
                "    \n",
                "    for x, y in tqdm(loader, desc=\"Train\", leave=False):\n",
                "        x, y = x.to(DEVICE, non_blocking=True), y.to(DEVICE, non_blocking=True)\n",
                "        \n",
                "        with torch.amp.autocast('cuda'):\n",
                "            logits = model(x).logits\n",
                "            if use_mixup:\n",
                "                loss = -torch.sum(y * F.log_softmax(logits, 1), 1).mean()\n",
                "                labels = y.argmax(1)\n",
                "            else:\n",
                "                loss = F.cross_entropy(logits, y, label_smoothing=label_smoothing)\n",
                "                labels = y\n",
                "        \n",
                "        total_loss += loss.item()\n",
                "        correct += (logits.argmax(1) == labels).sum().item()\n",
                "        total += x.size(0)\n",
                "        \n",
                "        optimizer.zero_grad(set_to_none=True)\n",
                "        scaler.scale(loss).backward()\n",
                "        scaler.unscale_(optimizer)\n",
                "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
                "        scaler.step(optimizer)\n",
                "        scaler.update()\n",
                "        scheduler.step()\n",
                "        \n",
                "        del x, y, logits, loss\n",
                "    \n",
                "    return total_loss / len(loader), correct / total\n",
                "\n",
                "@torch.no_grad()\n",
                "def evaluate(model, loader, classes):\n",
                "    model.eval()\n",
                "    all_preds, all_ids = [], []\n",
                "    \n",
                "    for x, ids in tqdm(loader, desc=\"Eval\", leave=False):\n",
                "        x = x.to(DEVICE, non_blocking=True)\n",
                "        preds = model(x).logits.argmax(1).cpu().numpy()\n",
                "        all_preds.extend(preds.tolist())\n",
                "        all_ids.extend(ids.numpy().tolist())\n",
                "        del x, preds\n",
                "    \n",
                "    y_pred = [classes[p] for vid, p in zip(all_ids, all_preds) if str(vid) in TEST_LABELS]\n",
                "    y_true = [TEST_LABELS[str(vid)] for vid in all_ids if str(vid) in TEST_LABELS]\n",
                "    return accuracy_score(y_true, y_pred)\n",
                "\n",
                "def save_checkpoint(epoch, phase, loss, train_acc, test_acc, best_acc):\n",
                "    \"\"\"Save single checkpoint (overwrite) + append to CSV\"\"\"\n",
                "    # Save model (overwrite)\n",
                "    torch.save(model.state_dict(), 'checkpoint.pt')\n",
                "    \n",
                "    # Append to CSV\n",
                "    row = {'epoch': epoch, 'phase': phase, 'loss': loss, 'train_acc': train_acc, 'test_acc': test_acc, 'best_acc': best_acc}\n",
                "    df = pd.DataFrame([row])\n",
                "    if os.path.exists('history.csv'):\n",
                "        df.to_csv('history.csv', mode='a', header=False, index=False)\n",
                "    else:\n",
                "        df.to_csv('history.csv', index=False)\n",
                "    \n",
                "    print(f\"  Loss:{loss:.4f} | Train:{train_acc:.4f} | Test:{test_acc:.4f} | Best:{best_acc:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Check Resume"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "START_EPOCH = 1\n",
                "START_PHASE = 'P1'\n",
                "best_acc = 0\n",
                "\n",
                "if os.path.exists('history.csv') and os.path.exists('checkpoint.pt'):\n",
                "    df = pd.read_csv('history.csv')\n",
                "    last = df.iloc[-1]\n",
                "    \n",
                "    model.load_state_dict(torch.load('checkpoint.pt', map_location=DEVICE))\n",
                "    \n",
                "    last_epoch = int(last['epoch'])\n",
                "    START_PHASE = last['phase']\n",
                "    best_acc = float(last['best_acc'])\n",
                "    \n",
                "    if START_PHASE == 'P1':\n",
                "        START_EPOCH = last_epoch + 1\n",
                "    else:  # P2\n",
                "        START_EPOCH = last_epoch - EPOCHS_P1 + 1\n",
                "    \n",
                "    print(f\"‚úÖ Resume: epoch {last_epoch+1}, phase {START_PHASE}, best={best_acc:.4f}\")\n",
                "else:\n",
                "    print(\"üìù Starting fresh\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Phase 1: Mixup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if START_PHASE == 'P1' and START_EPOCH <= EPOCHS_P1:\n",
                "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR_P1, weight_decay=WEIGHT_DECAY)\n",
                "    total_steps = len(train_loader_p1) * EPOCHS_P1\n",
                "    scheduler = get_cosine_schedule_with_warmup(optimizer, int(total_steps*0.1), total_steps)\n",
                "    \n",
                "    # Fast-forward scheduler\n",
                "    for _ in range((START_EPOCH - 1) * len(train_loader_p1)):\n",
                "        scheduler.step()\n",
                "    \n",
                "    scaler = torch.amp.GradScaler()\n",
                "    \n",
                "    print(\"=\"*60)\n",
                "    print(f\"PHASE 1: Mixup | LR={LR_P1} | Epochs {START_EPOCH}-{EPOCHS_P1}\")\n",
                "    print(\"=\"*60)\n",
                "    \n",
                "    for ep in range(START_EPOCH, EPOCHS_P1 + 1):\n",
                "        print(f\"\\nEpoch {ep}/{EPOCHS_P1}\")\n",
                "        loss, train_acc = train_epoch(model, train_loader_p1, optimizer, scheduler, scaler, use_mixup=True)\n",
                "        test_acc = evaluate(model, test_loader, train_dataset.classes)\n",
                "        \n",
                "        if test_acc > best_acc:\n",
                "            best_acc = test_acc\n",
                "            torch.save({'model': model.state_dict(), 'classes': train_dataset.classes}, 'best.pt')\n",
                "            print(f\"  >>> New Best!\")\n",
                "        \n",
                "        save_checkpoint(ep, 'P1', loss, train_acc, test_acc, best_acc)\n",
                "        gc.collect(); torch.cuda.empty_cache()\n",
                "    \n",
                "    print(f\"\\nP1 Done! Best: {best_acc:.4f}\")\n",
                "    START_EPOCH = 1\n",
                "    START_PHASE = 'P2'\n",
                "else:\n",
                "    print(f\"Skipping P1\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Phase 2: Label Smoothing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if START_PHASE == 'P2':\n",
                "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR_P2, weight_decay=WEIGHT_DECAY)\n",
                "    total_steps = len(train_loader_p2) * EPOCHS_P2\n",
                "    scheduler = get_cosine_schedule_with_warmup(optimizer, 0, total_steps)\n",
                "    \n",
                "    p2_start = START_EPOCH if START_EPOCH > 1 else 1\n",
                "    for _ in range((p2_start - 1) * len(train_loader_p2)):\n",
                "        scheduler.step()\n",
                "    \n",
                "    scaler = torch.amp.GradScaler()\n",
                "    \n",
                "    print(\"\\n\" + \"=\"*60)\n",
                "    print(f\"PHASE 2: Label Smoothing | LR={LR_P2} | Epochs {p2_start}-{EPOCHS_P2}\")\n",
                "    print(\"=\"*60)\n",
                "    \n",
                "    for ep in range(p2_start, EPOCHS_P2 + 1):\n",
                "        global_ep = EPOCHS_P1 + ep\n",
                "        print(f\"\\nEpoch {global_ep}/{EPOCHS_P1+EPOCHS_P2}\")\n",
                "        loss, train_acc = train_epoch(model, train_loader_p2, optimizer, scheduler, scaler, use_mixup=False, label_smoothing=LABEL_SMOOTHING)\n",
                "        test_acc = evaluate(model, test_loader, train_dataset.classes)\n",
                "        \n",
                "        if test_acc > best_acc:\n",
                "            best_acc = test_acc\n",
                "            torch.save({'model': model.state_dict(), 'classes': train_dataset.classes}, 'best.pt')\n",
                "            print(f\"  >>> New Best!\")\n",
                "        \n",
                "        save_checkpoint(global_ep, 'P2', loss, train_acc, test_acc, best_acc)\n",
                "        gc.collect(); torch.cuda.empty_cache()\n",
                "    \n",
                "    print(f\"\\nüèÜ FINAL: {best_acc:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Plot"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if os.path.exists('history.csv'):\n",
                "    df = pd.read_csv('history.csv')\n",
                "    \n",
                "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
                "    axes[0].plot(df['epoch'], df['train_acc'], 'b-o', label='Train', ms=3)\n",
                "    axes[0].plot(df['epoch'], df['test_acc'], 'r-s', label='Test', ms=3)\n",
                "    axes[0].axvline(x=EPOCHS_P1, color='gray', ls='--', label='P1‚ÜíP2')\n",
                "    axes[0].set_title('Accuracy'); axes[0].legend(); axes[0].grid(alpha=0.3)\n",
                "    axes[1].plot(df['epoch'], df['loss'], 'g-^', ms=3)\n",
                "    axes[1].axvline(x=EPOCHS_P1, color='gray', ls='--')\n",
                "    axes[1].set_title('Loss'); axes[1].grid(alpha=0.3)\n",
                "    plt.tight_layout()\n",
                "    plt.savefig('curves.png', dpi=150)\n",
                "    plt.show()\n",
                "    print(df.to_string(index=False))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "kaggle": {
            "accelerator": "nvidiaTeslaT4",
            "dataSources": [
                {
                    "sourceId": 125907,
                    "sourceType": "competition"
                }
            ],
            "isInternetEnabled": true,
            "isGpuEnabled": true
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}