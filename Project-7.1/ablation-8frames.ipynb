{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NUM_FRAMES Comparison: 8 vs 16\n",
    "\n",
    "**2 Experiments on 2 GPUs:**\n",
    "- GPU 0: NUM_FRAMES=8, Paper Baseline\n",
    "- GPU 1: NUM_FRAMES=8, Full Custom (Consistent + Mixup + 2-Stage + Flip TTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown \"1Xv2CWOqdBj3kt0rkNJKRsodSIEd3-wX_\" -O test_labels.csv -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile worker_8frames_baseline.py\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"GPU 0: NUM_FRAMES=8, Paper Baseline\"\"\"\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import random, numpy as np, torch, torch.nn as nn, torch.nn.functional as F, time\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from transformers import VideoMAEForVideoClassification, VideoMAEImageProcessor, get_cosine_schedule_with_warmup\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "PATH_TRAIN = Path('/kaggle/input/action-video/data/data_train')\n",
    "PATH_TEST = Path('/kaggle/input/action-video/data/test')\n",
    "MODEL_CKPT = \"MCG-NJU/videomae-base-finetuned-kinetics\"\n",
    "NUM_FRAMES, IMG_SIZE, RESIZE = 8, 224, 256\n",
    "BATCH, ACCUM, EPOCHS, LR, WD = 20, 2, 10, 5e-5, 0.05\n",
    "device = torch.device('cuda:0')\n",
    "gpu_id = 0\n",
    "proc = VideoMAEImageProcessor.from_pretrained(MODEL_CKPT)\n",
    "MEAN, STD = proc.image_mean, proc.image_std\n",
    "\n",
    "class DS(Dataset):\n",
    "    def __init__(self, root):\n",
    "        self.root = Path(root)\n",
    "        self.classes = sorted([d.name for d in self.root.iterdir() if d.is_dir()])\n",
    "        self.c2i = {c:i for i,c in enumerate(self.classes)}\n",
    "        self.samples = [(v, self.c2i[c]) for c in self.classes for v in (self.root/c).iterdir() if v.is_dir()]\n",
    "    def __len__(self): return len(self.samples)\n",
    "    def __getitem__(self, i):\n",
    "        v, l = self.samples[i]\n",
    "        fs = sorted(v.glob('*.jpg'))\n",
    "        idx = torch.linspace(0, len(fs)-1, NUM_FRAMES).long()\n",
    "        fr = torch.stack([TF.to_tensor(Image.open(fs[j]).convert('RGB')) for j in idx])\n",
    "        s = random.uniform(0.8,1.0)\n",
    "        fr = TF.resize(fr, [int(fr.shape[-2]*s), int(fr.shape[-1]*s)])\n",
    "        i,j = random.randint(0,max(0,fr.shape[-2]-IMG_SIZE)), random.randint(0,max(0,fr.shape[-1]-IMG_SIZE))\n",
    "        fr = TF.resize(TF.crop(fr, i, j, min(IMG_SIZE,fr.shape[-2]), min(IMG_SIZE,fr.shape[-1])), [IMG_SIZE,IMG_SIZE])\n",
    "        if random.random()<0.5: fr = TF.hflip(fr)\n",
    "        return torch.stack([TF.normalize(f, MEAN, STD) for f in fr]), l\n",
    "\n",
    "class TDS(Dataset):\n",
    "    def __init__(self, root):\n",
    "        self.root = Path(root)\n",
    "        self.samples = sorted([(d,int(d.name)) for d in self.root.iterdir() if d.is_dir()], key=lambda x:x[1])\n",
    "    def __len__(self): return len(self.samples)\n",
    "    def __getitem__(self, i):\n",
    "        v, vid = self.samples[i]\n",
    "        fs = sorted(v.glob('*.jpg'))\n",
    "        idx = torch.linspace(0, len(fs)-1, NUM_FRAMES).long()\n",
    "        fr = [TF.resize(Image.open(fs[j]).convert('RGB'), RESIZE) for j in idx]\n",
    "        return torch.stack([TF.normalize(TF.to_tensor(TF.center_crop(f, IMG_SIZE)), MEAN, STD) for f in fr]), vid\n",
    "\n",
    "def train(m, ld, opt, sch, sc):\n",
    "    m.train()\n",
    "    loss_s, cor, tot = 0.0, 0, 0\n",
    "    for bi, (x, y) in enumerate(ld):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            logits = m(x).logits\n",
    "            loss = F.cross_entropy(logits, y)\n",
    "        cor += (logits.argmax(1)==y).sum().item()\n",
    "        tot += y.size(0)\n",
    "        loss_s += loss.item() * y.size(0)\n",
    "        sc.scale(loss/ACCUM).backward()\n",
    "        if (bi+1) % ACCUM == 0:\n",
    "            sc.unscale_(opt); torch.nn.utils.clip_grad_norm_(m.parameters(), 1.0)\n",
    "            sc.step(opt); sc.update(); opt.zero_grad(); sch.step()\n",
    "    return loss_s/tot, cor/tot\n",
    "\n",
    "def evalu(m, ld):\n",
    "    m.eval()\n",
    "    ps = []\n",
    "    with torch.no_grad():\n",
    "        for x, ids in ld:\n",
    "            ps.extend(zip(ids.tolist(), m(x.to(device)).logits.argmax(1).cpu().tolist()))\n",
    "    return ps\n",
    "\n",
    "print(f\"[GPU{gpu_id}] Exp: 8frames_baseline\")\n",
    "random.seed(42); np.random.seed(42); torch.manual_seed(42)\n",
    "tds = DS(PATH_TRAIN)\n",
    "tes = TDS(PATH_TEST)\n",
    "cn = tds.classes\n",
    "m = VideoMAEForVideoClassification.from_pretrained(MODEL_CKPT, num_labels=len(cn), ignore_mismatched_sizes=True, num_frames=NUM_FRAMES).to(device)\n",
    "tl = DataLoader(tds, BATCH, shuffle=True, num_workers=2, drop_last=True)\n",
    "tel = DataLoader(tes, BATCH, num_workers=2)\n",
    "opt = torch.optim.AdamW(m.parameters(), lr=LR, weight_decay=WD)\n",
    "sc = torch.amp.GradScaler()\n",
    "sch = get_cosine_schedule_with_warmup(opt, int(len(tl)*EPOCHS*0.1/ACCUM), len(tl)*EPOCHS//ACCUM)\n",
    "gt = dict(zip(pd.read_csv('test_labels.csv')['id'].astype(str), pd.read_csv('test_labels.csv')['class']))\n",
    "\n",
    "for ep in range(EPOCHS):\n",
    "    ep_start = time.time()\n",
    "    l, a = train(m, tl, opt, sch, sc)\n",
    "    ps = evalu(m, tel)\n",
    "    ta = accuracy_score([gt[str(i)] for i,_ in ps], [cn[p] for _,p in ps])\n",
    "    ep_time = time.time() - ep_start; eta = ep_time * (EPOCHS - ep - 1)\n",
    "    print(f\"  [GPU{gpu_id}] Ep{ep+1}/{EPOCHS}: L={l:.4f}, Atr={a:.4f}, Ate={ta:.4f} | {ep_time//60:.0f}m{ep_time%60:.0f}s | ETA: {eta//60:.0f}m{eta%60:.0f}s\", flush=True)\n",
    "\n",
    "ps = evalu(m, tel)\n",
    "fa = accuracy_score([gt[str(i)] for i,_ in ps], [cn[p] for _,p in ps])\n",
    "print(f\"  FINAL: {fa:.4f}\")\n",
    "pd.DataFrame([{'exp': '8frames_baseline', 'test_acc': fa, 'num_frames': 8, 'gpu': gpu_id}]).to_csv('results_8frames.csv', index=False)\n",
    "print(\"Saved results_8frames.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile worker_8frames_custom.py\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"GPU 1: NUM_FRAMES=8, Full Custom Flow\"\"\"\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import random, numpy as np, torch, torch.nn as nn, torch.nn.functional as F, time\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from transformers import VideoMAEForVideoClassification, VideoMAEImageProcessor, get_cosine_schedule_with_warmup\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "PATH_TRAIN = Path('/kaggle/input/action-video/data/data_train')\n",
    "PATH_TEST = Path('/kaggle/input/action-video/data/test')\n",
    "MODEL_CKPT = \"MCG-NJU/videomae-base-finetuned-kinetics\"\n",
    "NUM_FRAMES, IMG_SIZE, RESIZE = 8, 224, 256\n",
    "BATCH, ACCUM, EPOCHS, LR, WD = 20, 2, 10, 5e-5, 0.05\n",
    "device = torch.device('cuda:0')\n",
    "gpu_id = 1\n",
    "proc = VideoMAEImageProcessor.from_pretrained(MODEL_CKPT)\n",
    "MEAN, STD = proc.image_mean, proc.image_std\n",
    "\n",
    "class DS(Dataset):\n",
    "    def __init__(self, root):\n",
    "        self.root = Path(root)\n",
    "        self.classes = sorted([d.name for d in self.root.iterdir() if d.is_dir()])\n",
    "        self.c2i = {c:i for i,c in enumerate(self.classes)}\n",
    "        self.samples = [(v, self.c2i[c]) for c in self.classes for v in (self.root/c).iterdir() if v.is_dir()]\n",
    "    def __len__(self): return len(self.samples)\n",
    "    def __getitem__(self, i):\n",
    "        v, l = self.samples[i]\n",
    "        fs = sorted(v.glob('*.jpg'))\n",
    "        idx = torch.linspace(0, len(fs)-1, NUM_FRAMES).long()\n",
    "        fr = [TF.resize(Image.open(fs[j]).convert('RGB'), RESIZE) for j in idx]\n",
    "        i,j,h,w = T.RandomResizedCrop.get_params(fr[0], (0.8,1.0), (0.75,1.33))\n",
    "        fl = random.random() > 0.5\n",
    "        return torch.stack([TF.normalize(TF.to_tensor(TF.hflip(TF.resized_crop(f,i,j,h,w,(IMG_SIZE,IMG_SIZE))) if fl else TF.resized_crop(f,i,j,h,w,(IMG_SIZE,IMG_SIZE))), MEAN, STD) for f in fr]), l\n",
    "\n",
    "class TDS(Dataset):\n",
    "    def __init__(self, root):\n",
    "        self.root = Path(root)\n",
    "        self.samples = sorted([(d,int(d.name)) for d in self.root.iterdir() if d.is_dir()], key=lambda x:x[1])\n",
    "    def __len__(self): return len(self.samples)\n",
    "    def __getitem__(self, i):\n",
    "        v, vid = self.samples[i]\n",
    "        fs = sorted(v.glob('*.jpg'))\n",
    "        idx = torch.linspace(0, len(fs)-1, NUM_FRAMES).long()\n",
    "        fr = [TF.resize(Image.open(fs[j]).convert('RGB'), RESIZE) for j in idx]\n",
    "        w,h = fr[0].size\n",
    "        views = []\n",
    "        for t,lf in [((h-IMG_SIZE)//2,(w-IMG_SIZE)//2), (0,(w-IMG_SIZE)//2), (max(0,h-IMG_SIZE),(w-IMG_SIZE)//2)]:\n",
    "            views.append(torch.stack([TF.normalize(TF.to_tensor(TF.crop(f,t,lf,IMG_SIZE,IMG_SIZE)), MEAN, STD) for f in fr]))\n",
    "            views.append(torch.stack([TF.normalize(TF.to_tensor(TF.hflip(TF.crop(f,t,lf,IMG_SIZE,IMG_SIZE))), MEAN, STD) for f in fr]))\n",
    "        return torch.stack(views), vid\n",
    "\n",
    "class Mix:\n",
    "    def __init__(self, nc, a=0.8): self.nc, self.a = nc, a\n",
    "    def __call__(self, b):\n",
    "        x,y = torch.utils.data.default_collate(b)\n",
    "        lam = np.random.beta(self.a, self.a)\n",
    "        i = torch.randperm(x.size(0))\n",
    "        return lam*x + (1-lam)*x[i], lam*F.one_hot(y,self.nc).float() + (1-lam)*F.one_hot(y[i],self.nc).float()\n",
    "\n",
    "def train(m, ld, opt, sch, sc, mix=False, ls=0.0):\n",
    "    m.train()\n",
    "    loss_s, cor, tot = 0.0, 0, 0\n",
    "    for bi, (x, y) in enumerate(ld):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            lo = m(x).logits\n",
    "            if mix:\n",
    "                loss = -torch.sum(y * F.log_softmax(lo,1), 1).mean()\n",
    "                lb = y.argmax(1)\n",
    "            else:\n",
    "                loss = F.cross_entropy(lo, y, label_smoothing=ls)\n",
    "                lb = y\n",
    "        cor += (lo.argmax(1)==lb).sum().item()\n",
    "        tot += lb.size(0)\n",
    "        loss_s += loss.item() * lb.size(0)\n",
    "        sc.scale(loss/ACCUM).backward()\n",
    "        if (bi+1) % ACCUM == 0:\n",
    "            sc.unscale_(opt); torch.nn.utils.clip_grad_norm_(m.parameters(), 1.0)\n",
    "            sc.step(opt); sc.update(); opt.zero_grad(); sch.step()\n",
    "    return loss_s/tot, cor/tot\n",
    "\n",
    "def evalu(m, ld, multi=True):\n",
    "    m.eval()\n",
    "    ps = []\n",
    "    with torch.no_grad():\n",
    "        for x, ids in ld:\n",
    "            if multi:\n",
    "                B,V,T,C,H,W = x.shape\n",
    "                lo = m(x.view(B*V,T,C,H,W).to(device)).logits.view(B,V,-1).mean(1)\n",
    "            else:\n",
    "                lo = m(x.to(device)).logits\n",
    "            ps.extend(zip(ids.tolist(), lo.argmax(1).cpu().tolist()))\n",
    "    return ps\n",
    "\n",
    "print(f\"[GPU{gpu_id}] Exp: 8frames_custom_full\")\n",
    "random.seed(42); np.random.seed(42); torch.manual_seed(42)\n",
    "tds = DS(PATH_TRAIN)\n",
    "tes = TDS(PATH_TEST)\n",
    "cn = tds.classes\n",
    "m = VideoMAEForVideoClassification.from_pretrained(MODEL_CKPT, num_labels=len(cn), ignore_mismatched_sizes=True, num_frames=NUM_FRAMES).to(device)\n",
    "col = Mix(len(cn))\n",
    "tl = DataLoader(tds, BATCH, shuffle=True, num_workers=2, drop_last=True, collate_fn=col)\n",
    "tel = DataLoader(tes, 4, num_workers=2)\n",
    "opt = torch.optim.AdamW(m.parameters(), lr=LR, weight_decay=WD)\n",
    "sc = torch.amp.GradScaler()\n",
    "sch = get_cosine_schedule_with_warmup(opt, int(len(tl)*EPOCHS*0.1/ACCUM), len(tl)*EPOCHS//ACCUM)\n",
    "gt = dict(zip(pd.read_csv('test_labels.csv')['id'].astype(str), pd.read_csv('test_labels.csv')['class']))\n",
    "\n",
    "for ep in range(EPOCHS):\n",
    "    ep_start = time.time()\n",
    "    l, a = train(m, tl, opt, sch, sc, True, 0.0)\n",
    "    ps = evalu(m, tel, True)\n",
    "    ta = accuracy_score([gt[str(i)] for i,_ in ps], [cn[p] for _,p in ps])\n",
    "    ep_time = time.time() - ep_start; eta = ep_time * (EPOCHS + 3 - ep - 1)\n",
    "    print(f\"  [GPU{gpu_id}] Ep{ep+1}/{EPOCHS}: L={l:.4f}, Atr={a:.4f}, Ate={ta:.4f} | {ep_time//60:.0f}m{ep_time%60:.0f}s | ETA: {eta//60:.0f}m{eta%60:.0f}s\", flush=True)\n",
    "\n",
    "print(f\"  [GPU{gpu_id}] Phase 2...\")\n",
    "opt = torch.optim.AdamW(m.parameters(), lr=1e-6, weight_decay=WD)\n",
    "p2 = DataLoader(tds, BATCH, shuffle=True, num_workers=2, drop_last=True)\n",
    "sch = get_cosine_schedule_with_warmup(opt, 0, len(p2)*3//ACCUM)\n",
    "for ep in range(3):\n",
    "    ep_start = time.time()\n",
    "    l,a = train(m, p2, opt, sch, sc, False, 0.1)\n",
    "    ps = evalu(m, tel, True)\n",
    "    ta = accuracy_score([gt[str(i)] for i,_ in ps], [cn[p] for _,p in ps])\n",
    "    ep_time = time.time() - ep_start\n",
    "    print(f\"  [GPU{gpu_id}] P2Ep{ep+1}/3: L={l:.4f}, Atr={a:.4f}, Ate={ta:.4f} | {ep_time//60:.0f}m{ep_time%60:.0f}s\", flush=True)\n",
    "\n",
    "ps = evalu(m, tel, True)\n",
    "fa = accuracy_score([gt[str(i)] for i,_ in ps], [cn[p] for _,p in ps])\n",
    "print(f\"  FINAL: {fa:.4f}\")\n",
    "pd.DataFrame([{'exp': '8frames_custom_full', 'test_acc': fa, 'num_frames': 8, 'gpu': gpu_id}]).to_csv('results_8frames_custom.csv', index=False)\n",
    "print(\"Saved results_8frames_custom.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run Both Workers in Parallel\n",
    "import subprocess\n",
    "import threading\n",
    "\n",
    "def stream_output(proc, name):\n",
    "    for line in iter(proc.stdout.readline, ''):\n",
    "        if line:\n",
    "            print(f\"{line}\", end='', flush=True)\n",
    "    proc.stdout.close()\n",
    "\n",
    "print(\"Starting 2 workers...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "p0 = subprocess.Popen(['python', '-u', 'worker_8frames_baseline.py'], stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1)\n",
    "p1 = subprocess.Popen(['python', '-u', 'worker_8frames_custom.py'], stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1)\n",
    "\n",
    "t0 = threading.Thread(target=stream_output, args=(p0, 'GPU0'))\n",
    "t1 = threading.Thread(target=stream_output, args=(p1, 'GPU1'))\n",
    "t0.start(); t1.start()\n",
    "p0.wait(); p1.wait()\n",
    "t0.join(); t1.join()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Both workers finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compare Results\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df1 = pd.read_csv('results_8frames.csv')\n",
    "df2 = pd.read_csv('results_8frames_custom.csv')\n",
    "df = pd.concat([df1, df2])\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"8-FRAME RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# Compare with 16-frame (from main ablation)\n",
    "print(\"\\n--- Comparison with 16-frame baseline ---\")\n",
    "baseline_8 = df[df['exp'] == '8frames_baseline']['test_acc'].values[0]\n",
    "custom_8 = df[df['exp'] == '8frames_custom_full']['test_acc'].values[0]\n",
    "print(f\"8-frame Baseline:      {baseline_8:.4f}\")\n",
    "print(f\"8-frame Custom:        {custom_8:.4f}\")\n",
    "print(f\"\\nImprovement (8f custom vs baseline): {(custom_8 - baseline_8)*100:+.2f}%\")\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "bars = ax.bar(['8f\\nBaseline', '8f\\nCustom'], [baseline_8*100, custom_8*100], color=['#3498db', '#2ecc71'], edgecolor='black')\n",
    "ax.set_ylabel('Test Accuracy (%)')\n",
    "ax.set_title('NUM_FRAMES=8 Comparison', fontweight='bold')\n",
    "for bar, acc in zip(bars, [baseline_8, custom_8]):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, f'{acc*100:.2f}%', ha='center', fontweight='bold')\n",
    "ax.set_ylim([50, 100])\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}