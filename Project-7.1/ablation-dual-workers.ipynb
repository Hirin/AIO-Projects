{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VideoMAE Ablation Study - Dual GPU Workers\n",
    "\n",
    "**Flow:**\n",
    "1. Write 2 worker scripts (GPU 0, GPU 1)\n",
    "2. Run both workers in parallel\n",
    "3. Merge results and plot\n",
    "\n",
    "**10 Experiments (5 per GPU):**\n",
    "- GPU 0: Exp0, 2, 4, 6, 8\n",
    "- GPU 1: Exp1, 1b, 3, 5, 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Download Test Labels\n",
    "!gdown \"1Xv2CWOqdBj3kt0rkNJKRsodSIEd3-wX_\" -O test_labels.csv -q\n",
    "print(\"Downloaded test_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile worker_gpu0.py\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"Worker GPU 0 - 5 experiments\"\"\"\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import logging\n",
    "logging.getLogger('transformers').setLevel(logging.ERROR)\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "\n",
    "import random, numpy as np, torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from transformers import VideoMAEForVideoClassification, VideoMAEImageProcessor, get_cosine_schedule_with_warmup\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "import timm\n",
    "\n",
    "# Config\n",
    "PATH_TRAIN = Path('/kaggle/input/action-video/data/data_train')\n",
    "PATH_TEST = Path('/kaggle/input/action-video/data/test')\n",
    "MODEL_CKPT = \"MCG-NJU/videomae-base-finetuned-kinetics\"\n",
    "NUM_FRAMES, IMG_SIZE, RESIZE = 16, 224, 256\n",
    "BATCH, ACCUM, EPOCHS, LR, WD = 20, 2, 10, 5e-5, 0.05\n",
    "gpu_id = 0\n",
    "device = torch.device('cuda:0')\n",
    "proc = VideoMAEImageProcessor.from_pretrained(MODEL_CKPT)\n",
    "MEAN, STD = proc.image_mean, proc.image_std\n",
    "\n",
    "class ViT(nn.Module):\n",
    "    def __init__(self, nc):\n",
    "        super().__init__()\n",
    "        self.vit = timm.create_model('vit_small_patch16_224', pretrained=True, num_classes=0)\n",
    "        self.head = nn.Linear(self.vit.num_features, nc)\n",
    "    def forward(self, x):\n",
    "        B,T,C,H,W = x.shape\n",
    "        return self.head(self.vit(x.view(B*T,C,H,W)).view(B,T,-1).mean(1))\n",
    "\n",
    "class DS(Dataset):\n",
    "    def __init__(self, root, con=False):\n",
    "        self.root, self.con = Path(root), con\n",
    "        self.classes = sorted([d.name for d in self.root.iterdir() if d.is_dir()])\n",
    "        self.c2i = {c:i for i,c in enumerate(self.classes)}\n",
    "        self.samples = [(v, self.c2i[c]) for c in self.classes for v in (self.root/c).iterdir() if v.is_dir()]\n",
    "    def __len__(self): return len(self.samples)\n",
    "    def __getitem__(self, i):\n",
    "        v, l = self.samples[i]\n",
    "        fs = sorted(v.glob('*.jpg'))\n",
    "        idx = torch.linspace(0, len(fs)-1, NUM_FRAMES).long()\n",
    "        if self.con:\n",
    "            fr = [TF.resize(Image.open(fs[j]).convert('RGB'), RESIZE) for j in idx]\n",
    "            i,j,h,w = T.RandomResizedCrop.get_params(fr[0], (0.8,1.0), (0.75,1.33))\n",
    "            fl = random.random() > 0.5\n",
    "            return torch.stack([TF.normalize(TF.to_tensor(TF.hflip(TF.resized_crop(f,i,j,h,w,(IMG_SIZE,IMG_SIZE))) if fl else TF.resized_crop(f,i,j,h,w,(IMG_SIZE,IMG_SIZE))), MEAN, STD) for f in fr]), l\n",
    "        fr = torch.stack([TF.to_tensor(Image.open(fs[j]).convert('RGB')) for j in idx])\n",
    "        s = random.uniform(0.8,1.0)\n",
    "        fr = TF.resize(fr, [int(fr.shape[-2]*s), int(fr.shape[-1]*s)])\n",
    "        i,j = random.randint(0,max(0,fr.shape[-2]-IMG_SIZE)), random.randint(0,max(0,fr.shape[-1]-IMG_SIZE))\n",
    "        fr = TF.resize(TF.crop(fr, i, j, min(IMG_SIZE,fr.shape[-2]), min(IMG_SIZE,fr.shape[-1])), [IMG_SIZE,IMG_SIZE])\n",
    "        if random.random()<0.5: fr = TF.hflip(fr)\n",
    "        return torch.stack([TF.normalize(f, MEAN, STD) for f in fr]), l\n",
    "\n",
    "class TDS(Dataset):\n",
    "    def __init__(self, root, tta=False):\n",
    "        self.root, self.tta = Path(root), tta\n",
    "        self.samples = sorted([(d,int(d.name)) for d in self.root.iterdir() if d.is_dir()], key=lambda x:x[1])\n",
    "    def __len__(self): return len(self.samples)\n",
    "    def __getitem__(self, i):\n",
    "        v, vid = self.samples[i]\n",
    "        fs = sorted(v.glob('*.jpg'))\n",
    "        idx = torch.linspace(0, len(fs)-1, NUM_FRAMES).long()\n",
    "        fr = [TF.resize(Image.open(fs[j]).convert('RGB'), RESIZE) for j in idx]\n",
    "        if self.tta:\n",
    "            w,h = fr[0].size\n",
    "            views = []\n",
    "            for t,lf in [((h-IMG_SIZE)//2,(w-IMG_SIZE)//2), (0,(w-IMG_SIZE)//2), (max(0,h-IMG_SIZE),(w-IMG_SIZE)//2)]:\n",
    "                views.append(torch.stack([TF.normalize(TF.to_tensor(TF.crop(f,t,lf,IMG_SIZE,IMG_SIZE)), MEAN, STD) for f in fr]))\n",
    "                views.append(torch.stack([TF.normalize(TF.to_tensor(TF.hflip(TF.crop(f,t,lf,IMG_SIZE,IMG_SIZE))), MEAN, STD) for f in fr]))\n",
    "            return torch.stack(views), vid\n",
    "        return torch.stack([TF.normalize(TF.to_tensor(TF.center_crop(f, IMG_SIZE)), MEAN, STD) for f in fr]), vid\n",
    "\n",
    "class Mix:\n",
    "    def __init__(self, nc, a=0.8): self.nc, self.a = nc, a\n",
    "    def __call__(self, b):\n",
    "        x,y = torch.utils.data.default_collate(b)\n",
    "        lam = np.random.beta(self.a, self.a)\n",
    "        i = torch.randperm(x.size(0))\n",
    "        return lam*x + (1-lam)*x[i], lam*F.one_hot(y,self.nc).float() + (1-lam)*F.one_hot(y[i],self.nc).float()\n",
    "\n",
    "def train(m, ld, opt, sch, sc, mix=False, ls=0.0, vit=False):\n",
    "    m.train()\n",
    "    loss_s, cor, tot = 0.0, 0, 0\n",
    "    for bi, (x, y) in enumerate(ld):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            lo = m(x) if vit else m(x).logits\n",
    "            if mix:\n",
    "                loss = -torch.sum(y * F.log_softmax(lo,1), 1).mean()\n",
    "                lb = y.argmax(1)\n",
    "            else:\n",
    "                loss = F.cross_entropy(lo, y, label_smoothing=ls)\n",
    "                lb = y\n",
    "        cor += (lo.argmax(1)==lb).sum().item()\n",
    "        tot += lb.size(0)\n",
    "        loss_s += loss.item() * lb.size(0)\n",
    "        sc.scale(loss/ACCUM).backward()\n",
    "        if (bi+1) % ACCUM == 0:\n",
    "            sc.unscale_(opt)\n",
    "            torch.nn.utils.clip_grad_norm_(m.parameters(), 1.0)\n",
    "            sc.step(opt); sc.update(); opt.zero_grad(); sch.step()\n",
    "    return loss_s/tot, cor/tot\n",
    "\n",
    "def evalu(m, ld, multi=False, vit=False):\n",
    "    m.eval()\n",
    "    ps = []\n",
    "    with torch.no_grad():\n",
    "        for x, ids in ld:\n",
    "            if multi:\n",
    "                B,V,T,C,H,W = x.shape\n",
    "                lo = (m(x.view(B*V,T,C,H,W).to(device)) if vit else m(x.view(B*V,T,C,H,W).to(device)).logits).view(B,V,-1).mean(1)\n",
    "            else:\n",
    "                lo = m(x.to(device)) if vit else m(x.to(device)).logits\n",
    "            ps.extend(zip(ids.tolist(), lo.argmax(1).cpu().tolist()))\n",
    "    return ps\n",
    "\n",
    "EXPS = [\n",
    "    {'name': 'Exp0_ViT', 'vit': True},\n",
    "    {'name': 'Exp2_Consistent', 'con': True},\n",
    "    {'name': 'Exp4_Mixup', 'con': True, 'mix': True},\n",
    "    {'name': 'Exp6_2Stage', 'con': True, 'mix': True, 'two': True},\n",
    "    {'name': 'Exp8_LR_High', 'con': True, 'mix': True, 'two': True, 'tta': True, 'lr': 1.25e-4},\n",
    "]\n",
    "\n",
    "def main():\n",
    "    gt = dict(zip(pd.read_csv('test_labels.csv')['id'].astype(str), pd.read_csv('test_labels.csv')['class']))\n",
    "    res = []\n",
    "    for e in EXPS:\n",
    "        print(f\"\\n[GPU0] {e['name']}\")\n",
    "        random.seed(42); np.random.seed(42); torch.manual_seed(42)\n",
    "        lr = e.get('lr', LR)\n",
    "        tds = DS(PATH_TRAIN, e.get('con'))\n",
    "        tes = TDS(PATH_TEST, e.get('tta'))\n",
    "        cn = tds.classes\n",
    "        m = ViT(len(cn)).to(device) if e.get('vit') else VideoMAEForVideoClassification.from_pretrained(MODEL_CKPT, num_labels=len(cn), ignore_mismatched_sizes=True, num_frames=NUM_FRAMES).to(device)\n",
    "        col = Mix(len(cn)) if e.get('mix') else None\n",
    "        tl = DataLoader(tds, BATCH, shuffle=True, num_workers=2, drop_last=True, collate_fn=col)\n",
    "        tel = DataLoader(tes, 4 if e.get('tta') else BATCH, num_workers=2)\n",
    "        opt = torch.optim.AdamW(m.parameters(), lr=lr, weight_decay=WD)\n",
    "        sc = torch.amp.GradScaler()\n",
    "        sch = get_cosine_schedule_with_warmup(opt, int(len(tl)*EPOCHS*0.1/ACCUM), len(tl)*EPOCHS//ACCUM)\n",
    "        for ep in range(EPOCHS):\n",
    "            import time\n",
    "            ep_start = time.time()\n",
    "            l, a = train(m, tl, opt, sch, sc, e.get('mix'), 0.0, e.get('vit'))\n",
    "            ps = evalu(m, tel, e.get('tta'), e.get('vit'))\n",
    "            ta = accuracy_score([gt[str(i)] for i,_ in ps], [cn[p] for _,p in ps])\n",
    "            ep_time = time.time() - ep_start; eta = ep_time * (EPOCHS - ep - 1); print(f\"  [GPU{gpu_id}] Ep{ep+1}/{EPOCHS}: L={l:.4f}, Atr={a:.4f}, Ate={ta:.4f} | {ep_time//60:.0f}m{ep_time%60:.0f}s | ETA: {eta//60:.0f}m{eta%60:.0f}s\")\n",
    "        if e.get('two'):\n",
    "            opt = torch.optim.AdamW(m.parameters(), lr=1e-6, weight_decay=WD)\n",
    "            p2 = DataLoader(tds, BATCH, shuffle=True, num_workers=2, drop_last=True)\n",
    "            sch = get_cosine_schedule_with_warmup(opt, 0, len(p2)*3//ACCUM)\n",
    "            for ep in range(3):\n",
    "                l,a = train(m, p2, opt, sch, sc, False, 0.1, e.get('vit'))\n",
    "                ps = evalu(m, tel, e.get('tta'), e.get('vit'))\n",
    "                ta = accuracy_score([gt[str(i)] for i,_ in ps], [cn[p] for _,p in ps])\n",
    "                print(f\"  P2Ep{ep+1}: L={l:.4f}, Atr={a:.4f}, Ate={ta:.4f}\")\n",
    "        ps = evalu(m, tel, e.get('tta'), e.get('vit'))\n",
    "        fa = accuracy_score([gt[str(i)] for i,_ in ps], [cn[p] for _,p in ps])\n",
    "        print(f\"  FINAL: {fa:.4f}\")\n",
    "        res.append({'exp': e['name'], 'test_acc': fa, 'lr': lr, 'gpu': 0})\n",
    "        # Save checkpoint after each exp\n",
    "        pd.DataFrame(res).to_csv(f\"results_gpu{gpu_id}_checkpoint.csv\", index=False)\n",
    "        print(f\"  Checkpoint saved: {len(res)} experiments completed\")\n",
    "        del m; torch.cuda.empty_cache()\n",
    "    pd.DataFrame(res).to_csv('results_gpu0.csv', index=False)\n",
    "    print(\"Saved results_gpu0.csv\")\n",
    "\n",
    "if __name__ == '__main__': main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile worker_gpu1.py\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"Worker GPU 1 - 5 experiments\"\"\"\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import logging\n",
    "logging.getLogger('transformers').setLevel(logging.ERROR)\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "\n",
    "import random, numpy as np, torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from transformers import VideoMAEForVideoClassification, VideoMAEImageProcessor, get_cosine_schedule_with_warmup\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "PATH_TRAIN = Path('/kaggle/input/action-video/data/data_train')\n",
    "PATH_TEST = Path('/kaggle/input/action-video/data/test')\n",
    "MODEL_CKPT = \"MCG-NJU/videomae-base-finetuned-kinetics\"\n",
    "NUM_FRAMES, IMG_SIZE, RESIZE = 16, 224, 256\n",
    "BATCH, ACCUM, EPOCHS, LR, WD = 20, 2, 10, 5e-5, 0.05\n",
    "gpu_id = 1\n",
    "device = torch.device('cuda:0')\n",
    "proc = VideoMAEImageProcessor.from_pretrained(MODEL_CKPT)\n",
    "MEAN, STD = proc.image_mean, proc.image_std\n",
    "\n",
    "class DS(Dataset):\n",
    "    def __init__(self, root, con=False):\n",
    "        self.root, self.con = Path(root), con\n",
    "        self.classes = sorted([d.name for d in self.root.iterdir() if d.is_dir()])\n",
    "        self.c2i = {c:i for i,c in enumerate(self.classes)}\n",
    "        self.samples = [(v, self.c2i[c]) for c in self.classes for v in (self.root/c).iterdir() if v.is_dir()]\n",
    "    def __len__(self): return len(self.samples)\n",
    "    def __getitem__(self, i):\n",
    "        v, l = self.samples[i]\n",
    "        fs = sorted(v.glob('*.jpg'))\n",
    "        idx = torch.linspace(0, len(fs)-1, NUM_FRAMES).long()\n",
    "        if self.con:\n",
    "            fr = [TF.resize(Image.open(fs[j]).convert('RGB'), RESIZE) for j in idx]\n",
    "            i,j,h,w = T.RandomResizedCrop.get_params(fr[0], (0.8,1.0), (0.75,1.33))\n",
    "            fl = random.random() > 0.5\n",
    "            return torch.stack([TF.normalize(TF.to_tensor(TF.hflip(TF.resized_crop(f,i,j,h,w,(IMG_SIZE,IMG_SIZE))) if fl else TF.resized_crop(f,i,j,h,w,(IMG_SIZE,IMG_SIZE))), MEAN, STD) for f in fr]), l\n",
    "        fr = torch.stack([TF.to_tensor(Image.open(fs[j]).convert('RGB')) for j in idx])\n",
    "        s = random.uniform(0.8,1.0)\n",
    "        fr = TF.resize(fr, [int(fr.shape[-2]*s), int(fr.shape[-1]*s)])\n",
    "        i,j = random.randint(0,max(0,fr.shape[-2]-IMG_SIZE)), random.randint(0,max(0,fr.shape[-1]-IMG_SIZE))\n",
    "        fr = TF.resize(TF.crop(fr, i, j, min(IMG_SIZE,fr.shape[-2]), min(IMG_SIZE,fr.shape[-1])), [IMG_SIZE,IMG_SIZE])\n",
    "        if random.random()<0.5: fr = TF.hflip(fr)\n",
    "        return torch.stack([TF.normalize(f, MEAN, STD) for f in fr]), l\n",
    "\n",
    "class TDS(Dataset):\n",
    "    def __init__(self, root, tta=False, mv=False):\n",
    "        self.root, self.tta, self.mv = Path(root), tta, mv\n",
    "        self.samples = sorted([(d,int(d.name)) for d in self.root.iterdir() if d.is_dir()], key=lambda x:x[1])\n",
    "    def __len__(self): return len(self.samples)\n",
    "    def __getitem__(self, i):\n",
    "        v, vid = self.samples[i]\n",
    "        fs = sorted(v.glob('*.jpg'))\n",
    "        idx = torch.linspace(0, len(fs)-1, NUM_FRAMES).long()\n",
    "        fr = [TF.resize(Image.open(fs[j]).convert('RGB'), RESIZE) for j in idx]\n",
    "        if self.tta:\n",
    "            w,h = fr[0].size\n",
    "            views = []\n",
    "            for t,lf in [((h-IMG_SIZE)//2,(w-IMG_SIZE)//2), (0,(w-IMG_SIZE)//2), (max(0,h-IMG_SIZE),(w-IMG_SIZE)//2)]:\n",
    "                views.append(torch.stack([TF.normalize(TF.to_tensor(TF.crop(f,t,lf,IMG_SIZE,IMG_SIZE)), MEAN, STD) for f in fr]))\n",
    "                views.append(torch.stack([TF.normalize(TF.to_tensor(TF.hflip(TF.crop(f,t,lf,IMG_SIZE,IMG_SIZE))), MEAN, STD) for f in fr]))\n",
    "            return torch.stack(views), vid\n",
    "        elif self.mv:\n",
    "            w,h = fr[0].size\n",
    "            views = []\n",
    "            for t,lf in [(0,0), ((h-IMG_SIZE)//2,(w-IMG_SIZE)//2), (max(0,h-IMG_SIZE),max(0,w-IMG_SIZE))]:\n",
    "                views.append(torch.stack([TF.normalize(TF.to_tensor(TF.crop(f,t,lf,IMG_SIZE,IMG_SIZE)), MEAN, STD) for f in fr]))\n",
    "            return torch.stack(views), vid\n",
    "        return torch.stack([TF.normalize(TF.to_tensor(TF.center_crop(f, IMG_SIZE)), MEAN, STD) for f in fr]), vid\n",
    "\n",
    "class Mix:\n",
    "    def __init__(self, nc, a=0.8): self.nc, self.a = nc, a\n",
    "    def __call__(self, b):\n",
    "        x,y = torch.utils.data.default_collate(b)\n",
    "        lam = np.random.beta(self.a, self.a)\n",
    "        i = torch.randperm(x.size(0))\n",
    "        return lam*x + (1-lam)*x[i], lam*F.one_hot(y,self.nc).float() + (1-lam)*F.one_hot(y[i],self.nc).float()\n",
    "\n",
    "def train(m, ld, opt, sch, sc, mix=False, ls=0.0):\n",
    "    m.train()\n",
    "    loss_s, cor, tot = 0.0, 0, 0\n",
    "    for bi, (x, y) in enumerate(ld):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            lo = m(x).logits\n",
    "            if mix:\n",
    "                loss = -torch.sum(y * F.log_softmax(lo,1), 1).mean()\n",
    "                lb = y.argmax(1)\n",
    "            else:\n",
    "                loss = F.cross_entropy(lo, y, label_smoothing=ls)\n",
    "                lb = y\n",
    "        cor += (lo.argmax(1)==lb).sum().item()\n",
    "        tot += lb.size(0)\n",
    "        loss_s += loss.item() * lb.size(0)\n",
    "        sc.scale(loss/ACCUM).backward()\n",
    "        if (bi+1) % ACCUM == 0:\n",
    "            sc.unscale_(opt)\n",
    "            torch.nn.utils.clip_grad_norm_(m.parameters(), 1.0)\n",
    "            sc.step(opt); sc.update(); opt.zero_grad(); sch.step()\n",
    "    return loss_s/tot, cor/tot\n",
    "\n",
    "def evalu(m, ld, multi=False):\n",
    "    m.eval()\n",
    "    ps = []\n",
    "    with torch.no_grad():\n",
    "        for x, ids in ld:\n",
    "            if multi:\n",
    "                B,V,T,C,H,W = x.shape\n",
    "                lo = m(x.view(B*V,T,C,H,W).to(device)).logits.view(B,V,-1).mean(1)\n",
    "            else:\n",
    "                lo = m(x.to(device)).logits\n",
    "            ps.extend(zip(ids.tolist(), lo.argmax(1).cpu().tolist()))\n",
    "    return ps\n",
    "\n",
    "EXPS = [\n",
    "    {'name': 'Exp1_VideoMAE'},\n",
    "    {'name': 'Exp1b_LR_High', 'lr': 1.25e-4},\n",
    "    {'name': 'Exp3_MultiSeg', 'mv': True},\n",
    "    {'name': 'Exp5_LabelSmooth', 'con': True, 'ls': 0.1},\n",
    "    {'name': 'Exp7_FlipTTA', 'con': True, 'mix': True, 'two': True, 'tta': True},\n",
    "]\n",
    "\n",
    "def main():\n",
    "    gt = dict(zip(pd.read_csv('test_labels.csv')['id'].astype(str), pd.read_csv('test_labels.csv')['class']))\n",
    "    res = []\n",
    "    for e in EXPS:\n",
    "        print(f\"\\n[GPU1] {e['name']}\")\n",
    "        random.seed(42); np.random.seed(42); torch.manual_seed(42)\n",
    "        lr = e.get('lr', LR)\n",
    "        tds = DS(PATH_TRAIN, e.get('con'))\n",
    "        tes = TDS(PATH_TEST, e.get('tta'), e.get('mv'))\n",
    "        cn = tds.classes\n",
    "        m = VideoMAEForVideoClassification.from_pretrained(MODEL_CKPT, num_labels=len(cn), ignore_mismatched_sizes=True, num_frames=NUM_FRAMES).to(device)\n",
    "        col = Mix(len(cn)) if e.get('mix') else None\n",
    "        tl = DataLoader(tds, BATCH, shuffle=True, num_workers=2, drop_last=True, collate_fn=col)\n",
    "        tel = DataLoader(tes, 4 if e.get('tta') or e.get('mv') else BATCH, num_workers=2)\n",
    "        opt = torch.optim.AdamW(m.parameters(), lr=lr, weight_decay=WD)\n",
    "        sc = torch.amp.GradScaler()\n",
    "        sch = get_cosine_schedule_with_warmup(opt, int(len(tl)*EPOCHS*0.1/ACCUM), len(tl)*EPOCHS//ACCUM)\n",
    "        for ep in range(EPOCHS):\n",
    "            import time\n",
    "            ep_start = time.time()\n",
    "            l, a = train(m, tl, opt, sch, sc, e.get('mix'), e.get('ls', 0.0))\n",
    "            ps = evalu(m, tel, e.get('tta') or e.get('mv'))\n",
    "            ta = accuracy_score([gt[str(i)] for i,_ in ps], [cn[p] for _,p in ps])\n",
    "            ep_time = time.time() - ep_start; eta = ep_time * (EPOCHS - ep - 1); print(f\"  [GPU{gpu_id}] Ep{ep+1}/{EPOCHS}: L={l:.4f}, Atr={a:.4f}, Ate={ta:.4f} | {ep_time//60:.0f}m{ep_time%60:.0f}s | ETA: {eta//60:.0f}m{eta%60:.0f}s\")\n",
    "        if e.get('two'):\n",
    "            opt = torch.optim.AdamW(m.parameters(), lr=1e-6, weight_decay=WD)\n",
    "            p2 = DataLoader(tds, BATCH, shuffle=True, num_workers=2, drop_last=True)\n",
    "            sch = get_cosine_schedule_with_warmup(opt, 0, len(p2)*3//ACCUM)\n",
    "            for ep in range(3):\n",
    "                l,a = train(m, p2, opt, sch, sc, False, 0.1)\n",
    "                ps = evalu(m, tel, e.get('tta'))\n",
    "                ta = accuracy_score([gt[str(i)] for i,_ in ps], [cn[p] for _,p in ps])\n",
    "                print(f\"  P2Ep{ep+1}: L={l:.4f}, Atr={a:.4f}, Ate={ta:.4f}\")\n",
    "        ps = evalu(m, tel, e.get('tta') or e.get('mv'))\n",
    "        fa = accuracy_score([gt[str(i)] for i,_ in ps], [cn[p] for _,p in ps])\n",
    "        print(f\"  FINAL: {fa:.4f}\")\n",
    "        res.append({'exp': e['name'], 'test_acc': fa, 'lr': lr, 'gpu': 1})\n",
    "        # Save checkpoint after each exp\n",
    "        pd.DataFrame(res).to_csv(f\"results_gpu{gpu_id}_checkpoint.csv\", index=False)\n",
    "        print(f\"  Checkpoint saved: {len(res)} experiments completed\")\n",
    "        del m; torch.cuda.empty_cache()\n",
    "    pd.DataFrame(res).to_csv('results_gpu1.csv', index=False)\n",
    "    print(\"Saved results_gpu1.csv\")\n",
    "\n",
    "if __name__ == '__main__': main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Run Both Workers in Parallel (Real-time Output)\nimport subprocess\nimport sys\nimport threading\nimport time\n\ndef stream_output(proc, name):\n    \"\"\"Stream process output in real-time.\"\"\"\n    for line in iter(proc.stdout.readline, ''):\n        if line:\n            print(f\"{line}\", end='', flush=True)\n    proc.stdout.close()\n\nprint(\"Starting 2 workers in parallel...\")\nprint(\"=\"*60)\n\n# Start both processes with stdout pipe\np0 = subprocess.Popen(\n    ['python', '-u', 'worker_gpu0.py'],  # -u for unbuffered\n    stdout=subprocess.PIPE,\n    stderr=subprocess.STDOUT,\n    text=True,\n    bufsize=1\n)\np1 = subprocess.Popen(\n    ['python', '-u', 'worker_gpu1.py'],\n    stdout=subprocess.PIPE,\n    stderr=subprocess.STDOUT,\n    text=True,\n    bufsize=1\n)\n\n# Create threads to stream output\nt0 = threading.Thread(target=stream_output, args=(p0, 'GPU0'))\nt1 = threading.Thread(target=stream_output, args=(p1, 'GPU1'))\n\nt0.start()\nt1.start()\n\n# Wait for completion\np0.wait()\np1.wait()\nt0.join()\nt1.join()\n\nprint(\"=\"*60)\nprint(\"Both workers finished!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. Merge Results and Plot\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load results\n",
    "df0 = pd.read_csv('results_gpu0.csv')\n",
    "df1 = pd.read_csv('results_gpu1.csv')\n",
    "df = pd.concat([df0, df1]).sort_values('exp').reset_index(drop=True)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ALL RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# LR Comparison\n",
    "print(\"\\n--- LR Comparison ---\")\n",
    "lr_low = df[df['exp'] == 'Exp1_VideoMAE']['test_acc'].values[0]\n",
    "lr_high = df[df['exp'] == 'Exp1b_LR_High']['test_acc'].values[0]\n",
    "print(f\"LR 5e-5:    {lr_low:.4f}\")\n",
    "print(f\"LR 1.25e-4: {lr_high:.4f}\")\n",
    "print(f\"Difference: {(lr_low - lr_high)*100:+.2f}%\")\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "colors = ['#e74c3c' if 'High' in e or '1.25' in str(l) else '#3498db' for e, l in zip(df['exp'], df['lr'])]\n",
    "bars = ax.bar(range(len(df)), df['test_acc'] * 100, color=colors, edgecolor='black')\n",
    "\n",
    "ax.set_xticks(range(len(df)))\n",
    "ax.set_xticklabels([e.replace('Exp', '').replace('_', '\\n') for e in df['exp']], fontsize=9)\n",
    "ax.set_ylabel('Test Accuracy (%)', fontsize=12)\n",
    "ax.set_title('VideoMAE Ablation Study (Blue=LR 5e-5, Red=LR 1.25e-4)', fontsize=14, fontweight='bold')\n",
    "\n",
    "for bar, acc in zip(bars, df['test_acc']):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, f'{acc*100:.1f}%',\n",
    "            ha='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "ax.set_ylim([50, 100])\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}