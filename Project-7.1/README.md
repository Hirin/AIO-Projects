# Video Action Recognition - Ablation Study

## ğŸ“‹ Tá»•ng quan

Project thá»±c hiá»‡n **Video Action Recognition** trÃªn táº­p dá»¯ liá»‡u 51 action classes sá»­ dá»¥ng cÃ¡c model:
- **ViT-Small/Base** (ImageNet pretrained, frame-level)
- **VideoMAE** (Kinetics pretrained, video-level)

## ğŸ“Š Káº¿t quáº£

| Model | Configuration | Test Accuracy |
|-------|---------------|---------------|
| ViT-Small Baseline | 16 frames, 10 epochs | 69.22% |
| ViT-Base Baseline | 16 frames, 10 epochs | 73.73% |
| VideoMAE 8-Frame | 8 frames, 60 epochs | 83.00% |
| VideoMAE Baseline | 16 frames, 10 epochs | 83.92% |
| VideoMAE + Data Balance | + Focal Loss | 84.00% |
| VideoMAE + Layer Decay | + Mixup | 84.51% |
| **VideoMAE Phase 3** | Full pipeline | **85.10%** |

### Best Configuration (Phase 3)
```python
MODEL_TYPE = "videomae"
NUM_FRAMES = 16
USE_CONSISTENT_SPATIAL_AUG = True
USE_MIXUP = True
USE_LABEL_SMOOTHING = True
USE_TWO_PHASE = True
USE_FLIP_TTA = True
EPOCHS_P1 = 30
EPOCHS_P2 = 10
```

## ğŸ“ Cáº¥u trÃºc Project

```
Project-7.1/
â”œâ”€â”€ README.md
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ unified-ablation.ipynb      # Main notebook vá»›i toggle system
â”‚   â”œâ”€â”€ baseline-btc.ipynb          # Baseline experiments
â”‚   â””â”€â”€ project-7-1-phase-3.ipynb   # Phase 3 best result
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ create_unified_notebook.py  # Generator script
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ ablation_study_conclusion.md
â”‚   â”œâ”€â”€ baseline-btc-analysis.md
â”‚   â”œâ”€â”€ comparison-baseline-vs-phase3.md
â”‚   â””â”€â”€ phase3-videomae-analysis.md
â”œâ”€â”€ results/                    # Training results & visualizations
â””â”€â”€ data/                       # Dataset (not tracked)
```

## ğŸš€ Sá»­ dá»¥ng

### 1. Cháº¡y Ablation Study
Upload `unified-ablation.ipynb` lÃªn Kaggle vÃ  set cÃ¡c toggles theo configuration mong muá»‘n:

```python
# Quick test all pipelines
WARMUP = True

# Or run specific experiment
WARMUP = False
MODEL_TYPE = "videomae"
USE_MIXUP = True
USE_TWO_PHASE = True
# ...
```

### 2. Regenerate Notebook
```bash
python scripts/create_unified_notebook.py
```

## ğŸ”§ Configuration Toggles

| Toggle | MÃ´ táº£ | Default |
|--------|-------|---------|
| `WARMUP` | Test pipeline nhanh (5 batches/phase) | False |
| `MODEL_TYPE` | `vit_small` / `vit_base` / `videomae` | videomae |
| `NUM_FRAMES` | Sá»‘ frames per video | 16 |
| `TRAIN_VAL_RATIO` | Tá»· lá»‡ train/val split | 0.9 |
| `USE_TEST_LABELS` | Download test labels Ä‘á»ƒ tÃ­nh accuracy | True |
| `USE_CONSISTENT_SPATIAL_AUG` | Same crop/flip cho all frames | True |
| `USE_MIXUP` | Mixup augmentation (Î±=0.8) | True |
| `USE_FOCAL_LOSS` | Focal Loss cho imbalanced data | False |
| `USE_LABEL_SMOOTHING` | Label smoothing (Îµ=0.1) | True |
| `USE_TWO_PHASE` | 2-Phase: Mixup â†’ Label Smoothing | True |
| `USE_LAYER_DECAY` | Layer-wise LR decay | False |
| `USE_FLIP_TTA` | 6-view TTA (3 crops Ã— 2 flip) | True |

## ğŸ“ˆ Training Pipeline

### Two-Phase Training
1. **Phase 1** (30 epochs): Mixup + High LR (5e-5)
2. **Phase 2** (10 epochs): Label Smoothing + Low LR (1e-6)

### Data Augmentation
- Consistent spatial augmentation (same crop/flip across frames)
- Mixup vá»›i Î±=0.8
- 6-view TTA at inference

## ğŸ“š Dependencies

```
torch >= 2.0
torchvision
timm
transformers
scikit-learn
pandas
matplotlib
tqdm
```

## ğŸ“ License

MIT License
